{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import numpy as np\n",
    "import pickle as pkl\n",
    "\n",
    "from gensim.models.fasttext import load_facebook_vectors\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.svm import SVC "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "songs = pd.read_csv(\"../resource/asnlib/publicdata/SingleLabel.csv\")\n",
    "songs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": false,
     "locked": true,
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../resource/asnlib/publicdata/subset.pkl\", \"rb\") as f:\n",
    "    embeddings = pkl.load(f)\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PART 1. Preprocess the data and create a variable `song_words`\n",
    "# that contains a list with one entry for each row in the `songs` dataframe.\n",
    "# Each entry should be a list of the tokenized words for that song's lyrics,\n",
    "# as specified in the lab document.\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "# tokenizing words\n",
    "song_words_unfiltered = []\n",
    "song_words = []\n",
    "\n",
    "lyrics = songs[\"lyrics\"].to_numpy()\n",
    "\n",
    "for song in lyrics:\n",
    "    tokenized = word_tokenize(song)\n",
    "    \n",
    "    # convert to lowercase\n",
    "    lowered = []\n",
    "    for word in tokenized:\n",
    "        lowered.append(word.lower())\n",
    "    song_words_unfiltered.append(lowered)\n",
    "\n",
    "# removing stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "for song in song_words_unfiltered:\n",
    "    song_filtered = []\n",
    "    for word in song:\n",
    "        if word not in stop_words:\n",
    "            song_filtered.append(word)\n",
    "    song_words.append(song_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Preprocess the data",
     "locked": true,
     "points": "10",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 2. Create the song embeddings and store them as a matrix in a variable `X`\n",
    "# where the rows are the songs and the columns are the vector dimensions.\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "\n",
    "# each song\n",
    "def avg(song, embeddings):\n",
    "    word_vecs = []\n",
    "    # each word in song\n",
    "    for word in song:\n",
    "        # add word vector or zero vector\n",
    "        if word in embeddings.keys():\n",
    "            word_vecs.append(embeddings[word])\n",
    "        else:\n",
    "            word_vecs.append(np.zeros(300))\n",
    "    # average word vectors, collect averages\n",
    "    return np.mean(word_vecs, axis=0)\n",
    "\n",
    "X = np.array([avg(song, embeddings) for song in song_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Represent the text with embeddings",
     "locked": true,
     "points": "20",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PART 3. Train the predictors as described in the lab document.\n",
    "# Create a variable `accuracy` storing the accuracy of the best model,\n",
    "# as well as a variable `n_vecs` storing the number of support vectors.\n",
    "\n",
    "###\n",
    "### YOUR CODE HERE\n",
    "###\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# target mood labels\n",
    "y = songs[\"label\"]\n",
    "\n",
    "# create SVMs\n",
    "parameters = {\n",
    "    'C': [.00001, .0001, .001, .01, .1, 1],\n",
    "    'gamma': [0.00001, 0.00005, 0.0001, 0.0005, 0.001, 0.005],\n",
    "    'kernel': ['poly', 'rbf']\n",
    "}\n",
    "\n",
    "svm = SVC()\n",
    "clf = GridSearchCV(svm, parameters, cv=5, scoring='accuracy', verbose=1)\n",
    "\n",
    "# finding accuracy and number of support vectors of best model <3\n",
    "clf.fit(X, y)\n",
    "y_pred = clf.predict(X)\n",
    "accuracy = accuracy_score(y, y_pred)\n",
    "n_vecs = clf.best_estimator_.n_support_.sum()\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Number of support vectors:\", n_vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": false,
    "editable": false,
    "nbgrader": {
     "grade": true,
     "grade_id": "Predict the label",
     "locked": true,
     "points": "20",
     "solution": false
    }
   },
   "outputs": [],
   "source": [
    "###\n",
    "### AUTOGRADER TEST - DO NOT REMOVE\n",
    "###\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# PART 4. Answer the discussion questions in comments here.\n",
    "\n",
    "# No, it is not a good model.\n",
    "\n",
    "# 1. The accuracy score is 0.49. This means that the model has less than a 50% chance\n",
    "#    of correctly labeling the song's emotion. That sucks! Random guessing would yield an\n",
    "#    accuracy score of around 0.11; the model's accuracy score isn't super close to that,\n",
    "#    but it is definitely not far enough.\n",
    "\n",
    "# 2. The number of support vectors is 917. The number of songs the model was trained on is\n",
    "#    1160. This means that the vast majority of the songs were determining factors for\n",
    "#    classification, which also sucks. It means that the model is way too complex; it is\n",
    "#    trying to map closely to the training data, meaning that it would generalize really\n",
    "#    poorly. And even now, the accuracy is still really bad."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [3.7]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
